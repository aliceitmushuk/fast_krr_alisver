{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeops.torch import LazyTensor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f01e810e330>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_nys_appx(K, n, r, device):\n",
    "    # # Calculate sketch\n",
    "    # Phi = torch.randn((r, n), device=device) / (n ** 0.5)\n",
    "    # Phi = torch.linalg.qr(Phi.t(), mode='reduced')[0].t()\n",
    "\n",
    "    # Y = K @ Phi\n",
    "\n",
    "    # # Calculate shift\n",
    "    # shift = torch.finfo(Y.dtype).eps\n",
    "    # Y_shifted = Y + shift * Phi\n",
    "\n",
    "    # # Calculate Phi^T * K * Phi (w/ shift) for Cholesky\n",
    "    # choleskytarget = torch.mm(Y_shifted, Phi.t())\n",
    "\n",
    "    # # Perform Cholesky decomposition\n",
    "    # C = torch.cholesky(choleskytarget)\n",
    "\n",
    "    # B = torch.linalg.solve_triangular(C, Y_shifted, upper=False, left=True)\n",
    "    # # B = V * S * U^T b/c we have been using transposed sketch\n",
    "    # _, S, UT = torch.linalg.svd(B, full_matrices=False)\n",
    "    # U = UT.t()\n",
    "    # S = torch.max(torch.square(S) - shift, torch.tensor(0.0))\n",
    "\n",
    "    Phi = torch.randn((n, r), device=device) / (n ** 0.5)\n",
    "    Phi = torch.linalg.qr(Phi, mode='reduced')[0]\n",
    "\n",
    "    Y = K @ Phi\n",
    "\n",
    "    # Calculate shift\n",
    "    shift = torch.finfo(Y.dtype).eps\n",
    "    Y_shifted = Y + shift * Phi\n",
    "\n",
    "    # Calculate Phi^T * K * Phi (w/ shift) for Cholesky\n",
    "    choleskytarget = torch.mm(Phi.t(), Y_shifted)\n",
    "\n",
    "    # Perform Cholesky decomposition\n",
    "    C = torch.linalg.cholesky(choleskytarget)\n",
    "\n",
    "    B = torch.linalg.solve_triangular(C, Y_shifted, upper=False, left=False)\n",
    "    U, S, _ = torch.linalg.svd(B, full_matrices=False)\n",
    "\n",
    "    return U, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(K, b, lambd, a):\n",
    "    return 1/2 * torch.dot(a, K @ a) + lambd / 2 * torch.dot(a, a) \\\n",
    "            - torch.dot(b, a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(K, b, lambd, a0, rho, eta, r, max_iter, device):\n",
    "    n = K.shape[0]\n",
    "    U, S = rand_nys_appx(K, n, r, device)\n",
    "\n",
    "    print(S)\n",
    "\n",
    "    a = a0\n",
    "    for i in range(max_iter):\n",
    "        g = K @ a + lambd * a - b\n",
    "        UTg = U.t() @ g\n",
    "        dir = U @ (UTg / (S + rho)) + 1/rho * (g - U @ UTg)\n",
    "        a -= eta * dir\n",
    "\n",
    "        print(f\"iter {i}, loss {loss(K, b, lambd, a)}\")\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sizes\n",
    "N_x = 100000  # Number of rows in x\n",
    "\n",
    "# Generate random data\n",
    "x = torch.randn(N_x, 3, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "# Define your LazyTensors\n",
    "x_i = LazyTensor(x[:, None, :])  # Shape (N_x, 1, 3)\n",
    "x_j = LazyTensor(x[None, :, :])  # Shape (1, N_y, 3)\n",
    "\n",
    "# Compute the Gaussian kernel matrix\n",
    "sigma = 1.0  # Kernel width\n",
    "D_ij = ((x_i - x_j) ** 2).sum(dim=2)  # Squared Euclidean distances\n",
    "K_ij = (- D_ij / (2 * sigma ** 2)).exp()  # Gaussian kernel matrix, still lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(N_x, dtype=torch.float32).to(device)\n",
    "lambd = 0.1 #(10 ** -2) / N_x\n",
    "a0 = torch.zeros(N_x, dtype=torch.float32).to(device)\n",
    "rho = 1\n",
    "eta = 0.1\n",
    "r = 300\n",
    "max_iter = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-499782.3438, device='cuda:1', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Ground truth\n",
    "a_star = K_ij.solve(torch.unsqueeze(b, 1), alpha=lambd)\n",
    "print(loss(K_ij, b, lambd, torch.squeeze(a_star)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Generating code for Sum_Reduction reduction (with parameters 0) of formula Exp(-Sum((a-b)**2)/c)*d with a=Var(0,3,0), b=Var(1,3,1), c=Var(2,1,2), d=Var(3,300,1) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
      "tensor([2.3684e+04, 1.0568e+04, 8.3558e+03, 6.8744e+03, 4.4076e+03, 3.9470e+03,\n",
      "        3.5008e+03, 3.4824e+03, 2.9372e+03, 2.8672e+03, 1.4879e+03, 1.4264e+03,\n",
      "        1.3339e+03, 1.2991e+03, 1.2640e+03, 1.1475e+03, 1.0914e+03, 1.0576e+03,\n",
      "        8.8882e+02, 8.5418e+02, 6.0365e+02, 5.1151e+02, 5.0499e+02, 4.9226e+02,\n",
      "        4.5720e+02, 4.4892e+02, 4.2948e+02, 4.0319e+02, 3.7124e+02, 3.6689e+02,\n",
      "        3.4061e+02, 3.1722e+02, 3.0162e+02, 2.7605e+02, 2.6736e+02, 2.4264e+02,\n",
      "        2.0505e+02, 1.9472e+02, 1.8041e+02, 1.7577e+02, 1.6111e+02, 1.5797e+02,\n",
      "        1.5218e+02, 1.4019e+02, 1.3867e+02, 1.3269e+02, 1.2823e+02, 1.2123e+02,\n",
      "        1.1646e+02, 1.1114e+02, 1.0653e+02, 1.0517e+02, 9.7843e+01, 9.0713e+01,\n",
      "        8.4984e+01, 8.1909e+01, 7.3373e+01, 6.6048e+01, 6.3652e+01, 6.1084e+01,\n",
      "        5.8440e+01, 5.5477e+01, 5.3183e+01, 5.2983e+01, 5.0641e+01, 4.6492e+01,\n",
      "        4.5237e+01, 4.2784e+01, 4.0647e+01, 3.9183e+01, 3.8865e+01, 3.6655e+01,\n",
      "        3.6367e+01, 3.4415e+01, 3.3922e+01, 3.3636e+01, 3.1611e+01, 3.0568e+01,\n",
      "        2.7905e+01, 2.7038e+01, 2.5920e+01, 2.5393e+01, 2.5012e+01, 2.2547e+01,\n",
      "        2.0257e+01, 1.9990e+01, 1.9190e+01, 1.8734e+01, 1.8152e+01, 1.7529e+01,\n",
      "        1.6453e+01, 1.5856e+01, 1.5476e+01, 1.4803e+01, 1.4422e+01, 1.3939e+01,\n",
      "        1.3254e+01, 1.3028e+01, 1.2577e+01, 1.1798e+01, 1.1679e+01, 1.1478e+01,\n",
      "        1.1155e+01, 1.0919e+01, 1.0159e+01, 9.7107e+00, 9.4392e+00, 9.2659e+00,\n",
      "        9.1064e+00, 8.9356e+00, 8.4403e+00, 8.1870e+00, 7.7245e+00, 7.5512e+00,\n",
      "        7.3641e+00, 7.1418e+00, 6.6672e+00, 6.5257e+00, 6.3769e+00, 6.0839e+00,\n",
      "        5.8826e+00, 5.5589e+00, 5.4674e+00, 5.2717e+00, 5.1256e+00, 4.8744e+00,\n",
      "        4.6814e+00, 4.6500e+00, 4.5149e+00, 4.4509e+00, 4.3261e+00, 4.2727e+00,\n",
      "        4.0829e+00, 4.0238e+00, 3.9946e+00, 3.9070e+00, 3.8553e+00, 3.7076e+00,\n",
      "        3.5575e+00, 3.5237e+00, 3.3891e+00, 3.3530e+00, 3.2676e+00, 3.2066e+00,\n",
      "        3.1729e+00, 3.0740e+00, 3.0262e+00, 2.9591e+00, 2.8526e+00, 2.8321e+00,\n",
      "        2.7795e+00, 2.6718e+00, 2.5993e+00, 2.4908e+00, 2.4201e+00, 2.3240e+00,\n",
      "        2.2843e+00, 2.2459e+00, 2.1774e+00, 2.0890e+00, 2.0663e+00, 2.0461e+00,\n",
      "        2.0158e+00, 1.9518e+00, 1.8809e+00, 1.7912e+00, 1.7621e+00, 1.7266e+00,\n",
      "        1.6399e+00, 1.6227e+00, 1.6182e+00, 1.5919e+00, 1.5107e+00, 1.4935e+00,\n",
      "        1.4372e+00, 1.4328e+00, 1.3965e+00, 1.3371e+00, 1.3192e+00, 1.2966e+00,\n",
      "        1.2517e+00, 1.2364e+00, 1.1850e+00, 1.1592e+00, 1.0899e+00, 1.0655e+00,\n",
      "        1.0610e+00, 1.0290e+00, 9.9810e-01, 9.4874e-01, 9.3245e-01, 8.9745e-01,\n",
      "        8.6329e-01, 8.3304e-01, 8.3181e-01, 8.1199e-01, 8.0089e-01, 7.7726e-01,\n",
      "        7.5135e-01, 7.3565e-01, 7.0952e-01, 6.8950e-01, 6.4896e-01, 6.3198e-01,\n",
      "        6.2201e-01, 5.9233e-01, 5.7429e-01, 5.5266e-01, 5.4332e-01, 5.3624e-01,\n",
      "        5.2189e-01, 5.1532e-01, 4.9486e-01, 4.6317e-01, 4.5583e-01, 4.3371e-01,\n",
      "        4.2039e-01, 4.1010e-01, 3.9926e-01, 3.8731e-01, 3.6089e-01, 3.4555e-01,\n",
      "        3.3751e-01, 3.2547e-01, 3.1811e-01, 3.0335e-01, 2.9567e-01, 2.8895e-01,\n",
      "        2.8115e-01, 2.7293e-01, 2.6681e-01, 2.6262e-01, 2.4416e-01, 2.3821e-01,\n",
      "        2.2919e-01, 2.2751e-01, 2.1746e-01, 2.1020e-01, 2.0798e-01, 1.9563e-01,\n",
      "        1.8196e-01, 1.7805e-01, 1.7219e-01, 1.6285e-01, 1.5742e-01, 1.5469e-01,\n",
      "        1.4298e-01, 1.3973e-01, 1.3504e-01, 1.3067e-01, 1.2320e-01, 1.1626e-01,\n",
      "        1.1531e-01, 1.1129e-01, 1.0397e-01, 1.0017e-01, 9.9171e-02, 9.5876e-02,\n",
      "        9.2305e-02, 8.8098e-02, 8.6155e-02, 8.3356e-02, 7.9301e-02, 7.8422e-02,\n",
      "        7.3368e-02, 6.9107e-02, 6.4918e-02, 6.3346e-02, 5.9336e-02, 5.7912e-02,\n",
      "        5.6655e-02, 5.3611e-02, 5.2833e-02, 5.0368e-02, 4.7444e-02, 4.5795e-02,\n",
      "        4.3432e-02, 4.1425e-02, 3.8342e-02, 3.6524e-02, 3.2371e-02, 3.0852e-02,\n",
      "        3.0338e-02, 2.8351e-02, 2.7437e-02, 2.6158e-02, 2.3350e-02, 2.1937e-02,\n",
      "        2.0126e-02, 1.8926e-02, 1.8463e-02, 1.6573e-02, 1.4237e-02, 1.4027e-02,\n",
      "        1.2684e-02, 1.1584e-02, 1.0632e-02, 9.5488e-03, 8.4439e-03, 5.1709e-03],\n",
      "       device='cuda:1')\n",
      "iter 0, loss -9974.9892578125\n",
      "iter 1, loss -19746.384765625\n",
      "iter 2, loss -29320.115234375\n",
      "iter 3, loss -38700.98828125\n",
      "iter 4, loss -47893.3671875\n",
      "iter 5, loss -56901.3359375\n",
      "iter 6, loss -65728.8125\n",
      "iter 7, loss -74379.5625\n",
      "iter 8, loss -82857.2265625\n",
      "iter 9, loss -91165.40625\n",
      "iter 10, loss -99307.5234375\n",
      "iter 11, loss -107286.9765625\n",
      "iter 12, loss -115107.0546875\n",
      "iter 13, loss -122770.9921875\n",
      "iter 14, loss -130281.953125\n",
      "iter 15, loss -137643.0\n",
      "iter 16, loss -144857.125\n",
      "iter 17, loss -151927.40625\n",
      "iter 18, loss -158856.5625\n",
      "iter 19, loss -165647.5625\n",
      "iter 20, loss -172303.078125\n",
      "iter 21, loss -178825.90625\n",
      "iter 22, loss -185218.640625\n",
      "iter 23, loss -191483.953125\n",
      "iter 24, loss -197624.34375\n",
      "iter 25, loss -203642.265625\n",
      "iter 26, loss -209540.359375\n",
      "iter 27, loss -215320.75\n",
      "iter 28, loss -220986.015625\n",
      "iter 29, loss -226538.40625\n",
      "iter 30, loss -231980.0625\n",
      "iter 31, loss -237313.359375\n",
      "iter 32, loss -242540.21875\n",
      "iter 33, loss -247663.09375\n",
      "iter 34, loss -252683.84375\n",
      "iter 35, loss -257604.546875\n",
      "iter 36, loss -262427.15625\n",
      "iter 37, loss -267153.6875\n",
      "iter 38, loss -271786.03125\n",
      "iter 39, loss -276326.09375\n",
      "iter 40, loss -280775.875\n",
      "iter 41, loss -285136.8125\n",
      "iter 42, loss -289411.0\n",
      "iter 43, loss -293599.9375\n",
      "iter 44, loss -297705.375\n",
      "iter 45, loss -301729.15625\n",
      "iter 46, loss -305672.875\n",
      "iter 47, loss -309537.9375\n",
      "iter 48, loss -313325.96875\n",
      "iter 49, loss -317038.5\n",
      "iter 50, loss -320677.21875\n",
      "iter 51, loss -324243.375\n",
      "iter 52, loss -327738.5625\n",
      "iter 53, loss -331164.125\n",
      "iter 54, loss -334521.25\n",
      "iter 55, loss -337811.9375\n",
      "iter 56, loss -341036.75\n",
      "iter 57, loss -344197.4375\n",
      "iter 58, loss -347295.125\n",
      "iter 59, loss -350331.0\n",
      "iter 60, loss -353306.75\n",
      "iter 61, loss -356223.15625\n",
      "iter 62, loss -359081.5\n",
      "iter 63, loss -361882.8125\n",
      "iter 64, loss -364628.15625\n",
      "iter 65, loss -367319.0625\n",
      "iter 66, loss -369956.28125\n",
      "iter 67, loss -372541.3125\n",
      "iter 68, loss -375074.21875\n",
      "iter 69, loss -377557.0625\n",
      "iter 70, loss -379990.8125\n",
      "iter 71, loss -382375.71875\n",
      "iter 72, loss -384712.84375\n",
      "iter 73, loss -387004.09375\n",
      "iter 74, loss -389249.1875\n",
      "iter 75, loss -391449.96875\n",
      "iter 76, loss -393606.5\n",
      "iter 77, loss -395720.375\n",
      "iter 78, loss -397792.125\n",
      "iter 79, loss -399822.625\n",
      "iter 80, loss -401812.6875\n",
      "iter 81, loss -403763.09375\n",
      "iter 82, loss -405674.6875\n",
      "iter 83, loss -407548.3125\n",
      "iter 84, loss -409384.21875\n",
      "iter 85, loss -411184.09375\n",
      "iter 86, loss -412947.75\n",
      "iter 87, loss -414676.5\n",
      "iter 88, loss -416370.75\n",
      "iter 89, loss -418031.3125\n",
      "iter 90, loss -419659.0625\n",
      "iter 91, loss -421253.9375\n",
      "iter 92, loss -422817.375\n",
      "iter 93, loss -424349.21875\n",
      "iter 94, loss -425851.1875\n",
      "iter 95, loss -427322.9375\n",
      "iter 96, loss -428765.4375\n",
      "iter 97, loss -430179.1875\n",
      "iter 98, loss -431564.9375\n",
      "iter 99, loss -432922.875\n",
      "iter 100, loss -434253.875\n",
      "iter 101, loss -435557.9375\n",
      "iter 102, loss -436836.3125\n",
      "iter 103, loss -438090.0\n",
      "iter 104, loss -439317.96875\n",
      "iter 105, loss -440521.6875\n",
      "iter 106, loss -441701.75\n",
      "iter 107, loss -442857.375\n",
      "iter 108, loss -443991.1875\n",
      "iter 109, loss -445101.6875\n",
      "iter 110, loss -446190.21875\n",
      "iter 111, loss -447256.75\n",
      "iter 112, loss -448302.25\n",
      "iter 113, loss -449327.1875\n",
      "iter 114, loss -450331.5\n",
      "iter 115, loss -451315.9375\n",
      "iter 116, loss -452280.6875\n",
      "iter 117, loss -453226.5\n",
      "iter 118, loss -454153.21875\n",
      "iter 119, loss -455061.625\n",
      "iter 120, loss -455951.875\n",
      "iter 121, loss -456824.25\n",
      "iter 122, loss -457679.625\n",
      "iter 123, loss -458517.5\n",
      "iter 124, loss -459338.75\n",
      "iter 125, loss -460143.84375\n",
      "iter 126, loss -460933.6875\n",
      "iter 127, loss -461706.75\n",
      "iter 128, loss -462464.75\n",
      "iter 129, loss -463207.0\n",
      "iter 130, loss -463935.1875\n",
      "iter 131, loss -464649.09375\n",
      "iter 132, loss -465348.6875\n",
      "iter 133, loss -466033.5625\n",
      "iter 134, loss -466705.625\n",
      "iter 135, loss -467363.9375\n",
      "iter 136, loss -468009.5625\n",
      "iter 137, loss -468642.125\n",
      "iter 138, loss -469261.96875\n",
      "iter 139, loss -469869.3125\n",
      "iter 140, loss -470465.0\n",
      "iter 141, loss -471047.875\n",
      "iter 142, loss -471619.875\n",
      "iter 143, loss -472180.5625\n",
      "iter 144, loss -472730.125\n",
      "iter 145, loss -473269.0\n",
      "iter 146, loss -473796.25\n",
      "iter 147, loss -474313.40625\n",
      "iter 148, loss -474820.65625\n",
      "iter 149, loss -475317.40625\n",
      "iter 150, loss -475804.5\n",
      "iter 151, loss -476281.25\n",
      "iter 152, loss -476750.0625\n",
      "iter 153, loss -477207.78125\n",
      "iter 154, loss -477657.625\n",
      "iter 155, loss -478098.25\n",
      "iter 156, loss -478529.53125\n",
      "iter 157, loss -478952.78125\n",
      "iter 158, loss -479367.15625\n",
      "iter 159, loss -479773.90625\n",
      "iter 160, loss -480171.59375\n",
      "iter 161, loss -480562.15625\n",
      "iter 162, loss -480945.0625\n",
      "iter 163, loss -481319.78125\n",
      "iter 164, loss -481687.28125\n",
      "iter 165, loss -482047.46875\n",
      "iter 166, loss -482400.125\n",
      "iter 167, loss -482746.8125\n",
      "iter 168, loss -483085.15625\n",
      "iter 169, loss -483417.9375\n",
      "iter 170, loss -483743.5625\n",
      "iter 171, loss -484062.5625\n",
      "iter 172, loss -484376.15625\n",
      "iter 173, loss -484682.4375\n",
      "iter 174, loss -484983.40625\n",
      "iter 175, loss -485277.34375\n",
      "iter 176, loss -485566.71875\n",
      "iter 177, loss -485849.65625\n",
      "iter 178, loss -486126.40625\n",
      "iter 179, loss -486398.71875\n",
      "iter 180, loss -486665.0\n",
      "iter 181, loss -486926.09375\n",
      "iter 182, loss -487182.34375\n",
      "iter 183, loss -487432.15625\n",
      "iter 184, loss -487679.4375\n",
      "iter 185, loss -487919.40625\n",
      "iter 186, loss -488156.59375\n",
      "iter 187, loss -488386.59375\n",
      "iter 188, loss -488613.625\n",
      "iter 189, loss -488836.25\n",
      "iter 190, loss -489053.9375\n",
      "iter 191, loss -489268.59375\n",
      "iter 192, loss -489477.25\n",
      "iter 193, loss -489682.625\n",
      "iter 194, loss -489883.5625\n",
      "iter 195, loss -490079.6875\n",
      "iter 196, loss -490273.34375\n",
      "iter 197, loss -490462.5625\n",
      "iter 198, loss -490647.75\n",
      "iter 199, loss -490830.65625\n",
      "iter 200, loss -491007.96875\n",
      "iter 201, loss -491182.5\n",
      "iter 202, loss -491353.90625\n",
      "iter 203, loss -491522.21875\n",
      "iter 204, loss -491685.71875\n",
      "iter 205, loss -491847.375\n",
      "iter 206, loss -492005.15625\n",
      "iter 207, loss -492160.65625\n",
      "iter 208, loss -492312.15625\n",
      "iter 209, loss -492460.53125\n",
      "iter 210, loss -492606.53125\n",
      "iter 211, loss -492748.65625\n",
      "iter 212, loss -492888.53125\n",
      "iter 213, loss -493026.28125\n",
      "iter 214, loss -493159.9375\n",
      "iter 215, loss -493292.9375\n",
      "iter 216, loss -493421.75\n",
      "iter 217, loss -493547.53125\n",
      "iter 218, loss -493672.25\n",
      "iter 219, loss -493794.125\n",
      "iter 220, loss -493914.28125\n",
      "iter 221, loss -494030.28125\n",
      "iter 222, loss -494144.53125\n",
      "iter 223, loss -494256.75\n",
      "iter 224, loss -494366.59375\n",
      "iter 225, loss -494475.25\n",
      "iter 226, loss -494580.375\n",
      "iter 227, loss -494684.28125\n",
      "iter 228, loss -494785.4375\n",
      "iter 229, loss -494885.53125\n",
      "iter 230, loss -494982.375\n",
      "iter 231, loss -495077.6875\n",
      "iter 232, loss -495171.96875\n",
      "iter 233, loss -495263.65625\n",
      "iter 234, loss -495353.4375\n",
      "iter 235, loss -495441.59375\n",
      "iter 236, loss -495528.03125\n",
      "iter 237, loss -495613.0\n",
      "iter 238, loss -495694.96875\n",
      "iter 239, loss -495776.53125\n",
      "iter 240, loss -495856.4375\n",
      "iter 241, loss -495935.21875\n",
      "iter 242, loss -496011.53125\n",
      "iter 243, loss -496086.5625\n",
      "iter 244, loss -496159.8125\n",
      "iter 245, loss -496231.84375\n",
      "iter 246, loss -496301.90625\n",
      "iter 247, loss -496372.125\n",
      "iter 248, loss -496439.59375\n",
      "iter 249, loss -496506.09375\n",
      "iter 250, loss -496572.25\n",
      "iter 251, loss -496635.90625\n",
      "iter 252, loss -496699.09375\n",
      "iter 253, loss -496759.625\n",
      "iter 254, loss -496819.34375\n",
      "iter 255, loss -496879.34375\n",
      "iter 256, loss -496936.09375\n",
      "iter 257, loss -496993.1875\n",
      "iter 258, loss -497048.875\n",
      "iter 259, loss -497103.5625\n",
      "iter 260, loss -497156.9375\n",
      "iter 261, loss -497208.5625\n",
      "iter 262, loss -497259.625\n",
      "iter 263, loss -497310.09375\n",
      "iter 264, loss -497358.5625\n",
      "iter 265, loss -497407.96875\n",
      "iter 266, loss -497455.0625\n",
      "iter 267, loss -497501.75\n",
      "iter 268, loss -497546.3125\n",
      "iter 269, loss -497591.09375\n",
      "iter 270, loss -497635.21875\n",
      "iter 271, loss -497676.8125\n",
      "iter 272, loss -497718.96875\n",
      "iter 273, loss -497761.40625\n",
      "iter 274, loss -497800.84375\n",
      "iter 275, loss -497840.8125\n",
      "iter 276, loss -497878.28125\n",
      "iter 277, loss -497917.25\n",
      "iter 278, loss -497954.875\n",
      "iter 279, loss -497990.90625\n",
      "iter 280, loss -498025.6875\n",
      "iter 281, loss -498060.625\n",
      "iter 282, loss -498095.53125\n",
      "iter 283, loss -498127.8125\n",
      "iter 284, loss -498161.84375\n",
      "iter 285, loss -498193.8125\n",
      "iter 286, loss -498225.65625\n",
      "iter 287, loss -498256.71875\n",
      "iter 288, loss -498287.0\n",
      "iter 289, loss -498316.625\n",
      "iter 290, loss -498346.03125\n",
      "iter 291, loss -498374.375\n",
      "iter 292, loss -498401.78125\n",
      "iter 293, loss -498430.40625\n",
      "iter 294, loss -498456.4375\n",
      "iter 295, loss -498483.5625\n",
      "iter 296, loss -498508.96875\n",
      "iter 297, loss -498533.5625\n",
      "iter 298, loss -498558.96875\n",
      "iter 299, loss -498583.375\n",
      "iter 300, loss -498608.09375\n",
      "iter 301, loss -498630.875\n",
      "iter 302, loss -498654.1875\n",
      "iter 303, loss -498676.90625\n",
      "iter 304, loss -498698.28125\n",
      "iter 305, loss -498719.21875\n",
      "iter 306, loss -498740.96875\n",
      "iter 307, loss -498762.0625\n",
      "iter 308, loss -498782.40625\n",
      "iter 309, loss -498802.65625\n",
      "iter 310, loss -498820.96875\n",
      "iter 311, loss -498840.5625\n",
      "iter 312, loss -498860.1875\n",
      "iter 313, loss -498877.96875\n",
      "iter 314, loss -498896.71875\n",
      "iter 315, loss -498913.28125\n",
      "iter 316, loss -498931.25\n",
      "iter 317, loss -498947.90625\n",
      "iter 318, loss -498964.5\n",
      "iter 319, loss -498981.0625\n",
      "iter 320, loss -498997.09375\n",
      "iter 321, loss -499011.84375\n",
      "iter 322, loss -499027.65625\n",
      "iter 323, loss -499042.96875\n",
      "iter 324, loss -499057.65625\n",
      "iter 325, loss -499071.8125\n",
      "iter 326, loss -499086.03125\n",
      "iter 327, loss -499099.53125\n",
      "iter 328, loss -499113.21875\n",
      "iter 329, loss -499127.21875\n",
      "iter 330, loss -499138.9375\n",
      "iter 331, loss -499153.15625\n",
      "iter 332, loss -499165.25\n",
      "iter 333, loss -499176.8125\n",
      "iter 334, loss -499189.71875\n",
      "iter 335, loss -499200.90625\n",
      "iter 336, loss -499212.84375\n",
      "iter 337, loss -499224.125\n",
      "iter 338, loss -499234.96875\n",
      "iter 339, loss -499246.59375\n",
      "iter 340, loss -499256.84375\n",
      "iter 341, loss -499266.9375\n",
      "iter 342, loss -499278.03125\n",
      "iter 343, loss -499286.9375\n",
      "iter 344, loss -499297.5625\n",
      "iter 345, loss -499307.875\n",
      "iter 346, loss -499316.375\n",
      "iter 347, loss -499326.34375\n",
      "iter 348, loss -499334.59375\n",
      "iter 349, loss -499343.625\n",
      "iter 350, loss -499352.9375\n",
      "iter 351, loss -499361.34375\n",
      "iter 352, loss -499369.53125\n",
      "iter 353, loss -499377.84375\n",
      "iter 354, loss -499385.90625\n",
      "iter 355, loss -499393.375\n",
      "iter 356, loss -499401.4375\n",
      "iter 357, loss -499408.71875\n",
      "iter 358, loss -499416.75\n",
      "iter 359, loss -499423.40625\n",
      "iter 360, loss -499431.46875\n",
      "iter 361, loss -499437.46875\n",
      "iter 362, loss -499445.09375\n",
      "iter 363, loss -499451.65625\n",
      "iter 364, loss -499457.46875\n",
      "iter 365, loss -499464.59375\n",
      "iter 366, loss -499470.625\n",
      "iter 367, loss -499478.0625\n",
      "iter 368, loss -499483.78125\n",
      "iter 369, loss -499489.21875\n",
      "iter 370, loss -499495.28125\n",
      "iter 371, loss -499501.09375\n",
      "iter 372, loss -499506.53125\n",
      "iter 373, loss -499512.21875\n",
      "iter 374, loss -499517.46875\n",
      "iter 375, loss -499522.65625\n",
      "iter 376, loss -499527.75\n",
      "iter 377, loss -499532.75\n",
      "iter 378, loss -499538.0\n",
      "iter 379, loss -499543.25\n",
      "iter 380, loss -499546.4375\n",
      "iter 381, loss -499552.6875\n",
      "iter 382, loss -499556.90625\n",
      "iter 383, loss -499561.90625\n",
      "iter 384, loss -499566.34375\n",
      "iter 385, loss -499569.84375\n",
      "iter 386, loss -499573.5\n",
      "iter 387, loss -499577.40625\n",
      "iter 388, loss -499582.15625\n",
      "iter 389, loss -499586.75\n",
      "iter 390, loss -499590.625\n",
      "iter 391, loss -499594.46875\n",
      "iter 392, loss -499597.65625\n",
      "iter 393, loss -499601.5\n",
      "iter 394, loss -499605.09375\n",
      "iter 395, loss -499607.71875\n",
      "iter 396, loss -499612.21875\n",
      "iter 397, loss -499615.53125\n",
      "iter 398, loss -499618.90625\n",
      "iter 399, loss -499622.21875\n",
      "iter 400, loss -499625.96875\n",
      "iter 401, loss -499629.40625\n",
      "iter 402, loss -499632.21875\n",
      "iter 403, loss -499634.53125\n",
      "iter 404, loss -499636.84375\n",
      "iter 405, loss -499640.71875\n",
      "iter 406, loss -499643.34375\n",
      "iter 407, loss -499646.65625\n",
      "iter 408, loss -499649.59375\n",
      "iter 409, loss -499651.40625\n",
      "iter 410, loss -499654.875\n",
      "iter 411, loss -499657.875\n",
      "iter 412, loss -499660.21875\n",
      "iter 413, loss -499660.53125\n",
      "iter 414, loss -499663.25\n",
      "iter 415, loss -499666.75\n",
      "iter 416, loss -499669.0\n",
      "iter 417, loss -499671.03125\n",
      "iter 418, loss -499673.09375\n",
      "iter 419, loss -499675.75\n",
      "iter 420, loss -499677.25\n",
      "iter 421, loss -499679.5625\n",
      "iter 422, loss -499681.8125\n",
      "iter 423, loss -499683.03125\n",
      "iter 424, loss -499686.09375\n",
      "iter 425, loss -499688.1875\n",
      "iter 426, loss -499688.9375\n",
      "iter 427, loss -499691.125\n",
      "iter 428, loss -499693.375\n",
      "iter 429, loss -499694.84375\n",
      "iter 430, loss -499696.59375\n",
      "iter 431, loss -499698.375\n",
      "iter 432, loss -499700.28125\n",
      "iter 433, loss -499702.03125\n",
      "iter 434, loss -499703.78125\n",
      "iter 435, loss -499705.59375\n",
      "iter 436, loss -499705.5625\n",
      "iter 437, loss -499708.375\n",
      "iter 438, loss -499709.25\n",
      "iter 439, loss -499710.78125\n",
      "iter 440, loss -499712.5625\n",
      "iter 441, loss -499713.84375\n",
      "iter 442, loss -499715.375\n",
      "iter 443, loss -499716.4375\n",
      "iter 444, loss -499717.71875\n",
      "iter 445, loss -499718.78125\n",
      "iter 446, loss -499720.15625\n",
      "iter 447, loss -499721.40625\n",
      "iter 448, loss -499722.84375\n",
      "iter 449, loss -499724.0625\n",
      "iter 450, loss -499726.15625\n",
      "iter 451, loss -499726.0625\n",
      "iter 452, loss -499728.3125\n",
      "iter 453, loss -499728.21875\n",
      "iter 454, loss -499729.53125\n",
      "iter 455, loss -499730.6875\n",
      "iter 456, loss -499732.03125\n",
      "iter 457, loss -499733.21875\n",
      "iter 458, loss -499733.9375\n",
      "iter 459, loss -499734.90625\n",
      "iter 460, loss -499735.96875\n",
      "iter 461, loss -499736.09375\n",
      "iter 462, loss -499738.4375\n",
      "iter 463, loss -499738.28125\n",
      "iter 464, loss -499739.28125\n",
      "iter 465, loss -499740.09375\n",
      "iter 466, loss -499740.75\n",
      "iter 467, loss -499742.15625\n",
      "iter 468, loss -499743.25\n",
      "iter 469, loss -499743.71875\n",
      "iter 470, loss -499744.8125\n",
      "iter 471, loss -499745.1875\n",
      "iter 472, loss -499746.21875\n",
      "iter 473, loss -499746.28125\n",
      "iter 474, loss -499747.59375\n",
      "iter 475, loss -499747.71875\n",
      "iter 476, loss -499748.71875\n",
      "iter 477, loss -499749.90625\n",
      "iter 478, loss -499749.40625\n",
      "iter 479, loss -499749.9375\n",
      "iter 480, loss -499750.625\n",
      "iter 481, loss -499752.0\n",
      "iter 482, loss -499752.875\n",
      "iter 483, loss -499753.65625\n",
      "iter 484, loss -499754.15625\n",
      "iter 485, loss -499753.875\n",
      "iter 486, loss -499754.5625\n",
      "iter 487, loss -499755.59375\n",
      "iter 488, loss -499756.0\n",
      "iter 489, loss -499756.75\n",
      "iter 490, loss -499756.53125\n",
      "iter 491, loss -499757.46875\n",
      "iter 492, loss -499757.3125\n",
      "iter 493, loss -499758.09375\n",
      "iter 494, loss -499759.4375\n",
      "iter 495, loss -499759.46875\n",
      "iter 496, loss -499760.25\n",
      "iter 497, loss -499760.46875\n",
      "iter 498, loss -499760.78125\n",
      "iter 499, loss -499760.6875\n",
      "iter 500, loss -499762.1875\n",
      "iter 501, loss -499761.34375\n",
      "iter 502, loss -499762.71875\n",
      "iter 503, loss -499763.0\n",
      "iter 504, loss -499764.03125\n",
      "iter 505, loss -499763.96875\n",
      "iter 506, loss -499764.1875\n",
      "iter 507, loss -499764.0625\n",
      "iter 508, loss -499764.65625\n",
      "iter 509, loss -499766.75\n",
      "iter 510, loss -499764.65625\n",
      "iter 511, loss -499766.9375\n",
      "iter 512, loss -499766.6875\n",
      "iter 513, loss -499766.625\n",
      "iter 514, loss -499766.90625\n",
      "iter 515, loss -499767.0\n",
      "iter 516, loss -499768.0\n",
      "iter 517, loss -499766.4375\n",
      "iter 518, loss -499768.71875\n",
      "iter 519, loss -499768.28125\n",
      "iter 520, loss -499768.53125\n",
      "iter 521, loss -499769.15625\n",
      "iter 522, loss -499769.625\n",
      "iter 523, loss -499769.625\n",
      "iter 524, loss -499769.09375\n",
      "iter 525, loss -499769.4375\n",
      "iter 526, loss -499770.625\n",
      "iter 527, loss -499770.65625\n",
      "iter 528, loss -499770.34375\n",
      "iter 529, loss -499770.75\n",
      "iter 530, loss -499770.90625\n",
      "iter 531, loss -499771.8125\n",
      "iter 532, loss -499771.3125\n",
      "iter 533, loss -499771.09375\n",
      "iter 534, loss -499772.4375\n",
      "iter 535, loss -499771.84375\n",
      "iter 536, loss -499772.875\n",
      "iter 537, loss -499773.0625\n",
      "iter 538, loss -499773.8125\n",
      "iter 539, loss -499773.65625\n",
      "iter 540, loss -499773.6875\n",
      "iter 541, loss -499774.0625\n",
      "iter 542, loss -499773.3125\n",
      "iter 543, loss -499773.5\n",
      "iter 544, loss -499774.28125\n",
      "iter 545, loss -499774.625\n",
      "iter 546, loss -499774.375\n",
      "iter 547, loss -499773.625\n",
      "iter 548, loss -499774.28125\n",
      "iter 549, loss -499774.5\n",
      "iter 550, loss -499774.90625\n",
      "iter 551, loss -499774.78125\n",
      "iter 552, loss -499775.34375\n",
      "iter 553, loss -499776.1875\n",
      "iter 554, loss -499775.6875\n",
      "iter 555, loss -499775.9375\n",
      "iter 556, loss -499776.1875\n",
      "iter 557, loss -499776.25\n",
      "iter 558, loss -499776.21875\n",
      "iter 559, loss -499777.3125\n",
      "iter 560, loss -499777.125\n",
      "iter 561, loss -499777.0\n",
      "iter 562, loss -499777.03125\n",
      "iter 563, loss -499777.5\n",
      "iter 564, loss -499777.25\n",
      "iter 565, loss -499777.8125\n",
      "iter 566, loss -499776.5\n",
      "iter 567, loss -499776.96875\n",
      "iter 568, loss -499777.5\n",
      "iter 569, loss -499777.8125\n",
      "iter 570, loss -499777.625\n",
      "iter 571, loss -499777.46875\n",
      "iter 572, loss -499778.1875\n",
      "iter 573, loss -499778.34375\n",
      "iter 574, loss -499778.53125\n",
      "iter 575, loss -499777.96875\n",
      "iter 576, loss -499777.8125\n",
      "iter 577, loss -499778.53125\n",
      "iter 578, loss -499779.09375\n",
      "iter 579, loss -499778.625\n",
      "iter 580, loss -499779.1875\n",
      "iter 581, loss -499778.3125\n",
      "iter 582, loss -499779.625\n",
      "iter 583, loss -499778.21875\n",
      "iter 584, loss -499778.65625\n",
      "iter 585, loss -499778.65625\n",
      "iter 586, loss -499779.34375\n",
      "iter 587, loss -499779.34375\n",
      "iter 588, loss -499779.59375\n",
      "iter 589, loss -499778.28125\n",
      "iter 590, loss -499779.5\n",
      "iter 591, loss -499779.09375\n",
      "iter 592, loss -499780.1875\n",
      "iter 593, loss -499779.5\n",
      "iter 594, loss -499780.34375\n",
      "iter 595, loss -499779.21875\n",
      "iter 596, loss -499779.375\n",
      "iter 597, loss -499779.28125\n",
      "iter 598, loss -499778.90625\n",
      "iter 599, loss -499780.1875\n",
      "iter 600, loss -499780.21875\n",
      "iter 601, loss -499779.71875\n",
      "iter 602, loss -499780.53125\n",
      "iter 603, loss -499780.40625\n",
      "iter 604, loss -499780.75\n",
      "iter 605, loss -499779.25\n",
      "iter 606, loss -499780.21875\n",
      "iter 607, loss -499779.5625\n",
      "iter 608, loss -499780.09375\n",
      "iter 609, loss -499780.03125\n",
      "iter 610, loss -499780.84375\n",
      "iter 611, loss -499781.28125\n",
      "iter 612, loss -499779.46875\n",
      "iter 613, loss -499781.21875\n",
      "iter 614, loss -499780.1875\n",
      "iter 615, loss -499780.28125\n",
      "iter 616, loss -499781.15625\n",
      "iter 617, loss -499781.875\n",
      "iter 618, loss -499780.53125\n",
      "iter 619, loss -499780.9375\n",
      "iter 620, loss -499781.03125\n",
      "iter 621, loss -499781.59375\n",
      "iter 622, loss -499780.6875\n",
      "iter 623, loss -499781.21875\n",
      "iter 624, loss -499781.625\n",
      "iter 625, loss -499781.53125\n",
      "iter 626, loss -499781.28125\n",
      "iter 627, loss -499781.59375\n",
      "iter 628, loss -499781.5\n",
      "iter 629, loss -499780.5625\n",
      "iter 630, loss -499781.0625\n",
      "iter 631, loss -499781.4375\n",
      "iter 632, loss -499780.96875\n",
      "iter 633, loss -499779.84375\n",
      "iter 634, loss -499782.21875\n",
      "iter 635, loss -499780.5625\n",
      "iter 636, loss -499780.59375\n",
      "iter 637, loss -499781.65625\n",
      "iter 638, loss -499781.03125\n",
      "iter 639, loss -499781.40625\n",
      "iter 640, loss -499781.125\n",
      "iter 641, loss -499781.8125\n",
      "iter 642, loss -499782.59375\n",
      "iter 643, loss -499781.8125\n",
      "iter 644, loss -499782.46875\n",
      "iter 645, loss -499782.59375\n",
      "iter 646, loss -499781.65625\n",
      "iter 647, loss -499781.9375\n",
      "iter 648, loss -499781.46875\n",
      "iter 649, loss -499780.96875\n",
      "iter 650, loss -499781.09375\n",
      "iter 651, loss -499781.84375\n",
      "iter 652, loss -499781.0625\n",
      "iter 653, loss -499782.125\n",
      "iter 654, loss -499781.21875\n",
      "iter 655, loss -499781.5\n",
      "iter 656, loss -499782.15625\n",
      "iter 657, loss -499782.34375\n",
      "iter 658, loss -499781.40625\n",
      "iter 659, loss -499781.9375\n",
      "iter 660, loss -499781.1875\n",
      "iter 661, loss -499782.1875\n",
      "iter 662, loss -499782.40625\n",
      "iter 663, loss -499781.4375\n",
      "iter 664, loss -499782.59375\n",
      "iter 665, loss -499781.375\n",
      "iter 666, loss -499782.25\n",
      "iter 667, loss -499781.15625\n",
      "iter 668, loss -499781.59375\n",
      "iter 669, loss -499781.78125\n",
      "iter 670, loss -499782.96875\n",
      "iter 671, loss -499781.8125\n",
      "iter 672, loss -499783.21875\n",
      "iter 673, loss -499782.25\n",
      "iter 674, loss -499782.59375\n",
      "iter 675, loss -499782.03125\n",
      "iter 676, loss -499782.03125\n",
      "iter 677, loss -499782.65625\n",
      "iter 678, loss -499782.0625\n",
      "iter 679, loss -499782.25\n",
      "iter 680, loss -499781.375\n",
      "iter 681, loss -499783.15625\n",
      "iter 682, loss -499782.125\n",
      "iter 683, loss -499782.5625\n",
      "iter 684, loss -499781.71875\n",
      "iter 685, loss -499781.875\n",
      "iter 686, loss -499782.90625\n",
      "iter 687, loss -499783.09375\n",
      "iter 688, loss -499783.0625\n",
      "iter 689, loss -499782.03125\n",
      "iter 690, loss -499782.96875\n",
      "iter 691, loss -499782.28125\n",
      "iter 692, loss -499781.84375\n",
      "iter 693, loss -499782.65625\n",
      "iter 694, loss -499781.78125\n",
      "iter 695, loss -499782.6875\n",
      "iter 696, loss -499781.9375\n",
      "iter 697, loss -499782.875\n",
      "iter 698, loss -499781.46875\n",
      "iter 699, loss -499782.46875\n",
      "iter 700, loss -499782.25\n",
      "iter 701, loss -499781.46875\n",
      "iter 702, loss -499781.6875\n",
      "iter 703, loss -499781.65625\n",
      "iter 704, loss -499781.84375\n",
      "iter 705, loss -499781.96875\n",
      "iter 706, loss -499781.78125\n",
      "iter 707, loss -499782.46875\n",
      "iter 708, loss -499782.90625\n",
      "iter 709, loss -499781.90625\n",
      "iter 710, loss -499782.25\n",
      "iter 711, loss -499782.625\n",
      "iter 712, loss -499782.1875\n",
      "iter 713, loss -499782.375\n",
      "iter 714, loss -499782.8125\n",
      "iter 715, loss -499781.90625\n",
      "iter 716, loss -499783.03125\n",
      "iter 717, loss -499781.9375\n",
      "iter 718, loss -499781.90625\n",
      "iter 719, loss -499782.71875\n",
      "iter 720, loss -499783.25\n",
      "iter 721, loss -499782.375\n",
      "iter 722, loss -499783.09375\n",
      "iter 723, loss -499781.625\n",
      "iter 724, loss -499782.59375\n",
      "iter 725, loss -499782.34375\n",
      "iter 726, loss -499782.34375\n",
      "iter 727, loss -499782.96875\n",
      "iter 728, loss -499782.75\n",
      "iter 729, loss -499782.8125\n",
      "iter 730, loss -499783.21875\n",
      "iter 731, loss -499782.875\n",
      "iter 732, loss -499782.5625\n",
      "iter 733, loss -499782.25\n",
      "iter 734, loss -499782.59375\n",
      "iter 735, loss -499782.3125\n",
      "iter 736, loss -499782.15625\n",
      "iter 737, loss -499782.46875\n",
      "iter 738, loss -499782.78125\n",
      "iter 739, loss -499783.15625\n",
      "iter 740, loss -499782.625\n",
      "iter 741, loss -499782.5\n",
      "iter 742, loss -499783.4375\n",
      "iter 743, loss -499782.8125\n",
      "iter 744, loss -499782.375\n",
      "iter 745, loss -499782.625\n",
      "iter 746, loss -499782.3125\n",
      "iter 747, loss -499782.34375\n",
      "iter 748, loss -499783.03125\n",
      "iter 749, loss -499781.46875\n",
      "iter 750, loss -499782.03125\n",
      "iter 751, loss -499782.59375\n",
      "iter 752, loss -499782.875\n",
      "iter 753, loss -499782.75\n",
      "iter 754, loss -499783.4375\n",
      "iter 755, loss -499782.59375\n",
      "iter 756, loss -499783.125\n",
      "iter 757, loss -499783.34375\n",
      "iter 758, loss -499783.5\n",
      "iter 759, loss -499782.75\n",
      "iter 760, loss -499782.5\n",
      "iter 761, loss -499782.78125\n",
      "iter 762, loss -499782.625\n",
      "iter 763, loss -499783.5\n",
      "iter 764, loss -499782.78125\n",
      "iter 765, loss -499782.5\n",
      "iter 766, loss -499783.03125\n",
      "iter 767, loss -499781.96875\n",
      "iter 768, loss -499783.71875\n",
      "iter 769, loss -499782.1875\n",
      "iter 770, loss -499782.84375\n",
      "iter 771, loss -499781.6875\n",
      "iter 772, loss -499782.375\n",
      "iter 773, loss -499782.4375\n",
      "iter 774, loss -499782.96875\n",
      "iter 775, loss -499782.25\n",
      "iter 776, loss -499782.71875\n",
      "iter 777, loss -499783.0\n",
      "iter 778, loss -499782.625\n",
      "iter 779, loss -499782.34375\n",
      "iter 780, loss -499782.21875\n",
      "iter 781, loss -499782.40625\n",
      "iter 782, loss -499782.96875\n",
      "iter 783, loss -499782.3125\n",
      "iter 784, loss -499782.75\n",
      "iter 785, loss -499782.625\n",
      "iter 786, loss -499782.78125\n",
      "iter 787, loss -499782.84375\n",
      "iter 788, loss -499782.9375\n",
      "iter 789, loss -499783.375\n",
      "iter 790, loss -499782.0\n",
      "iter 791, loss -499783.15625\n",
      "iter 792, loss -499782.90625\n",
      "iter 793, loss -499783.0\n",
      "iter 794, loss -499782.75\n",
      "iter 795, loss -499781.96875\n",
      "iter 796, loss -499782.84375\n",
      "iter 797, loss -499781.96875\n",
      "iter 798, loss -499782.34375\n",
      "iter 799, loss -499782.75\n",
      "iter 800, loss -499783.125\n",
      "iter 801, loss -499782.34375\n",
      "iter 802, loss -499782.78125\n",
      "iter 803, loss -499783.875\n",
      "iter 804, loss -499782.0625\n",
      "iter 805, loss -499782.5\n",
      "iter 806, loss -499781.21875\n",
      "iter 807, loss -499782.59375\n",
      "iter 808, loss -499782.28125\n",
      "iter 809, loss -499783.28125\n",
      "iter 810, loss -499783.75\n",
      "iter 811, loss -499782.78125\n",
      "iter 812, loss -499782.5625\n",
      "iter 813, loss -499783.75\n",
      "iter 814, loss -499782.875\n",
      "iter 815, loss -499782.3125\n",
      "iter 816, loss -499782.90625\n",
      "iter 817, loss -499781.8125\n",
      "iter 818, loss -499783.0\n",
      "iter 819, loss -499782.75\n",
      "iter 820, loss -499782.4375\n",
      "iter 821, loss -499783.125\n",
      "iter 822, loss -499782.5\n",
      "iter 823, loss -499782.59375\n",
      "iter 824, loss -499782.0\n",
      "iter 825, loss -499783.125\n",
      "iter 826, loss -499783.0\n",
      "iter 827, loss -499783.09375\n",
      "iter 828, loss -499782.125\n",
      "iter 829, loss -499781.90625\n",
      "iter 830, loss -499782.75\n",
      "iter 831, loss -499782.75\n",
      "iter 832, loss -499782.875\n",
      "iter 833, loss -499782.1875\n",
      "iter 834, loss -499783.5\n",
      "iter 835, loss -499782.5\n",
      "iter 836, loss -499782.59375\n",
      "iter 837, loss -499783.0625\n",
      "iter 838, loss -499782.25\n",
      "iter 839, loss -499783.84375\n",
      "iter 840, loss -499781.96875\n",
      "iter 841, loss -499782.0\n",
      "iter 842, loss -499781.21875\n",
      "iter 843, loss -499782.53125\n",
      "iter 844, loss -499782.78125\n",
      "iter 845, loss -499783.0625\n",
      "iter 846, loss -499783.21875\n",
      "iter 847, loss -499782.9375\n",
      "iter 848, loss -499782.34375\n",
      "iter 849, loss -499782.34375\n",
      "iter 850, loss -499782.96875\n",
      "iter 851, loss -499782.15625\n",
      "iter 852, loss -499783.25\n",
      "iter 853, loss -499783.03125\n",
      "iter 854, loss -499782.65625\n",
      "iter 855, loss -499783.03125\n",
      "iter 856, loss -499782.5\n",
      "iter 857, loss -499783.28125\n",
      "iter 858, loss -499781.71875\n",
      "iter 859, loss -499782.875\n",
      "iter 860, loss -499782.25\n",
      "iter 861, loss -499783.15625\n",
      "iter 862, loss -499782.4375\n",
      "iter 863, loss -499782.8125\n",
      "iter 864, loss -499782.65625\n",
      "iter 865, loss -499782.84375\n",
      "iter 866, loss -499783.9375\n",
      "iter 867, loss -499783.8125\n",
      "iter 868, loss -499783.0625\n",
      "iter 869, loss -499783.15625\n",
      "iter 870, loss -499783.0625\n",
      "iter 871, loss -499782.03125\n",
      "iter 872, loss -499782.875\n",
      "iter 873, loss -499782.9375\n",
      "iter 874, loss -499781.875\n",
      "iter 875, loss -499782.71875\n",
      "iter 876, loss -499783.0\n",
      "iter 877, loss -499782.96875\n",
      "iter 878, loss -499783.625\n",
      "iter 879, loss -499782.21875\n",
      "iter 880, loss -499783.28125\n",
      "iter 881, loss -499782.59375\n",
      "iter 882, loss -499782.5625\n",
      "iter 883, loss -499782.59375\n",
      "iter 884, loss -499781.875\n",
      "iter 885, loss -499781.34375\n",
      "iter 886, loss -499782.28125\n",
      "iter 887, loss -499782.625\n",
      "iter 888, loss -499783.09375\n",
      "iter 889, loss -499782.125\n",
      "iter 890, loss -499783.28125\n",
      "iter 891, loss -499782.09375\n",
      "iter 892, loss -499782.84375\n",
      "iter 893, loss -499782.9375\n",
      "iter 894, loss -499782.5625\n",
      "iter 895, loss -499783.15625\n",
      "iter 896, loss -499782.0625\n",
      "iter 897, loss -499782.09375\n",
      "iter 898, loss -499782.875\n",
      "iter 899, loss -499783.15625\n",
      "iter 900, loss -499782.84375\n",
      "iter 901, loss -499782.96875\n",
      "iter 902, loss -499783.15625\n",
      "iter 903, loss -499782.53125\n",
      "iter 904, loss -499783.875\n",
      "iter 905, loss -499783.0625\n",
      "iter 906, loss -499783.125\n",
      "iter 907, loss -499781.96875\n",
      "iter 908, loss -499782.71875\n",
      "iter 909, loss -499782.78125\n",
      "iter 910, loss -499782.375\n",
      "iter 911, loss -499782.6875\n",
      "iter 912, loss -499783.1875\n",
      "iter 913, loss -499782.5625\n",
      "iter 914, loss -499783.0\n",
      "iter 915, loss -499782.15625\n",
      "iter 916, loss -499783.3125\n",
      "iter 917, loss -499782.40625\n",
      "iter 918, loss -499782.59375\n",
      "iter 919, loss -499782.5\n",
      "iter 920, loss -499782.71875\n",
      "iter 921, loss -499782.40625\n",
      "iter 922, loss -499782.9375\n",
      "iter 923, loss -499782.78125\n",
      "iter 924, loss -499781.78125\n",
      "iter 925, loss -499782.46875\n",
      "iter 926, loss -499782.4375\n",
      "iter 927, loss -499781.90625\n",
      "iter 928, loss -499782.59375\n",
      "iter 929, loss -499782.96875\n",
      "iter 930, loss -499783.15625\n",
      "iter 931, loss -499782.6875\n",
      "iter 932, loss -499782.4375\n",
      "iter 933, loss -499782.59375\n",
      "iter 934, loss -499782.625\n",
      "iter 935, loss -499782.28125\n",
      "iter 936, loss -499782.9375\n",
      "iter 937, loss -499782.15625\n",
      "iter 938, loss -499782.78125\n",
      "iter 939, loss -499782.5625\n",
      "iter 940, loss -499782.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK_ij\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[95], line 9\u001b[0m, in \u001b[0;36mgd\u001b[0;34m(K, b, lambd, a0, rho, eta, r, max_iter, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m a \u001b[38;5;241m=\u001b[39m a0\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[0;32m----> 9\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[43mK\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m \u001b[38;5;241m+\u001b[39m lambd \u001b[38;5;241m*\u001b[39m a \u001b[38;5;241m-\u001b[39m b\n\u001b[1;32m     10\u001b[0m     UTg \u001b[38;5;241m=\u001b[39m U\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m@\u001b[39m g\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m U \u001b[38;5;241m@\u001b[39m (UTg \u001b[38;5;241m/\u001b[39m (S \u001b[38;5;241m+\u001b[39m rho)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mrho \u001b[38;5;241m*\u001b[39m (g \u001b[38;5;241m-\u001b[39m U \u001b[38;5;241m@\u001b[39m UTg)\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/pykeops/common/lazy_tensor.py:2524\u001b[0m, in \u001b[0;36mGenericLazyTensor.__matmul__\u001b[0;34m(self, v, **kwargs)\u001b[0m\n\u001b[1;32m   2522\u001b[0m v_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlt_constructor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mview(v, newdims))\n\u001b[1;32m   2523\u001b[0m Kv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m*\u001b[39m v_  \u001b[38;5;66;03m# Supports broadcasting\u001b[39;00m\n\u001b[0;32m-> 2524\u001b[0m Kv \u001b[38;5;241m=\u001b[39m \u001b[43mKv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Matrix-vector or Matrix-matrix product\u001b[39;00m\n\u001b[1;32m   2526\u001b[0m \u001b[38;5;66;03m# Expected behavior: if v is a vector, so should K @ v.\u001b[39;00m\n\u001b[1;32m   2527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools\u001b[38;5;241m.\u001b[39mview(Kv, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m Kv\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/pykeops/common/lazy_tensor.py:2096\u001b[0m, in \u001b[0;36mGenericLazyTensor.sum\u001b[0;34m(self, axis, dim, **kwargs)\u001b[0m\n\u001b[1;32m   2094\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munary(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum\u001b[39m\u001b[38;5;124m\"\u001b[39m, dimres\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2095\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/pykeops/common/lazy_tensor.py:775\u001b[0m, in \u001b[0;36mGenericLazyTensor.reduction\u001b[0;34m(self, reduction_op, other, opt_arg, axis, dim, call, is_complex, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m     res\u001b[38;5;241m.\u001b[39mcallfun \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mGenred(\n\u001b[1;32m    765\u001b[0m         res\u001b[38;5;241m.\u001b[39mformula,\n\u001b[1;32m    766\u001b[0m         [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    772\u001b[0m         rec_multVar_highdim\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mrec_multVar_highdim,\n\u001b[1;32m    773\u001b[0m     )\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39msymbolic_variables) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m res\u001b[38;5;241m.\u001b[39m_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mres\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/pykeops/common/lazy_tensor.py:957\u001b[0m, in \u001b[0;36mGenericLazyTensor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;66;03m# we replace by other\u001b[39;00m\n\u001b[1;32m    955\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mother\u001b[38;5;241m.\u001b[39mvariables[\u001b[38;5;241m0\u001b[39m],)\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/pykeops/torch/generic/generic_red.py:687\u001b[0m, in \u001b[0;36mGenred.__call__\u001b[0;34m(self, backend, device_id, ranges, out, *args)\u001b[0m\n\u001b[1;32m    685\u001b[0m params\u001b[38;5;241m.\u001b[39mny \u001b[38;5;241m=\u001b[39m ny\n\u001b[1;32m    686\u001b[0m params\u001b[38;5;241m.\u001b[39mout \u001b[38;5;241m=\u001b[39m out\n\u001b[0;32m--> 687\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mGenredAutograd_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m postprocess(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction_op, nout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_arg, dtype)\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/pykeops/torch/generic/generic_red.py:383\u001b[0m, in \u001b[0;36mGenredAutograd_fun\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGenredAutograd_fun\u001b[39m(\u001b[38;5;241m*\u001b[39minputs):\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGenredAutograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/torch/autograd/function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m     )\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/pykeops/torch/generic/generic_red.py:291\u001b[0m, in \u001b[0;36mGenredAutograd.forward\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39minputs):\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGenredAutograd_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/pykeops/torch/generic/generic_red.py:121\u001b[0m, in \u001b[0;36mGenredAutograd_base._forward\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params\u001b[38;5;241m.\u001b[39mranges:\n\u001b[1;32m    116\u001b[0m     params\u001b[38;5;241m.\u001b[39mranges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    117\u001b[0m         r\u001b[38;5;241m.\u001b[39mto(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mranges\n\u001b[1;32m    119\u001b[0m     )\n\u001b[0;32m--> 121\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmyconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenred_pytorch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mny\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnbatchdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, torch\u001b[38;5;241m.\u001b[39mtensor([myconv\u001b[38;5;241m.\u001b[39mdimout, myconv\u001b[38;5;241m.\u001b[39mtagIJ])\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/pykeops/common/keops_io/LoadKeOps.py:236\u001b[0m, in \u001b[0;36mLoadKeOps.genred\u001b[0;34m(self, device_args, ranges, nx, ny, nbatchdims, out, *args)\u001b[0m\n\u001b[1;32m    234\u001b[0m     out[:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_keops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mny\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpykeops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhalf2_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m postprocess_half2\n",
      "File \u001b[0;32m~/fast_krr/fast_krr_env/lib/python3.10/site-packages/pykeops/common/keops_io/LoadKeOps_nvrtc.py:48\u001b[0m, in \u001b[0;36mLoadKeOps_nvrtc_class.call_keops\u001b[0;34m(self, nx, ny)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_keops\u001b[39m(\u001b[38;5;28mself\u001b[39m, nx, ny):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch_keops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtagHostDevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mny\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtagI\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtagZero\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_half\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag1D2D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda_block_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_chunk_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindsi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindsj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindsp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimsx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimsy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimsp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mranges_ptr_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_ptr_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margshapes_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    a = gd(K_ij, b, lambd, a0, rho, eta, r, max_iter, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_krr_env",
   "language": "python",
   "name": "fast_krr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
