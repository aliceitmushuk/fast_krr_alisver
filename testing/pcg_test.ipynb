{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XCJx8hV8Q_gg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from src.opts.pcg import PCG\n",
        "from src.models.full_krr import FullKRR\n",
        "from src.models.inducing_krr import InducingKRR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6517fc0350>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2ATu6HeXXtu9"
      },
      "outputs": [],
      "source": [
        "ntr = 1000\n",
        "ntst = 100\n",
        "d = 3\n",
        "\n",
        "kernel_params = {\"type\": \"rbf\", \"sigma\": 1}\n",
        "lambd = 1\n",
        "task = \"regression\"\n",
        "device = 'cuda:2'\n",
        "m = 100\n",
        "\n",
        "precond_params_nys = {\"type\": \"nystrom\", \"r\": 100, \"rho\": 1}\n",
        "precond_params_greedy = {\"type\": \"partial_cholesky\", \"r\": 100, \"rho\": 1}\n",
        "precond_params_falkon = {\"type\": \"falkon\"}\n",
        "pcg_iters = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dQ27Zb8rs53T"
      },
      "outputs": [],
      "source": [
        "xtr = torch.randn(ntr, d).to(device)\n",
        "xtst = torch.randn(ntst, d).to(device)\n",
        "btr = torch.randn(ntr).to(device)\n",
        "btst = torch.randn(ntst).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Full KRR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[pyKeOps] Warning : at least one of the input tensors is not contiguous. Consider using contiguous data arrays to avoid unnecessary copies.\n",
            "PCG has converged with residual 9.202072419611795e-07 at iteration 8\n"
          ]
        }
      ],
      "source": [
        "w0 = torch.zeros(ntr).to(device)\n",
        "model = FullKRR(xtr, btr, xtst, btst, kernel_params, lambd, task, w0, device)\n",
        "opt = PCG(model, inducing=False, precond_params=precond_params_nys)\n",
        "opt.run(pcg_iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCG has converged with residual 8.849667096910707e-07 at iteration 9\n"
          ]
        }
      ],
      "source": [
        "w0 = torch.zeros(ntr).to(device)\n",
        "model = FullKRR(xtr, btr, xtst, btst, kernel_params, lambd, task, w0, device)\n",
        "opt = PCG(model, inducing=False, precond_params=precond_params_greedy)\n",
        "opt.run(pcg_iters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inducing KRR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "inducing_pts = torch.randperm(xtr.shape[0])[:m]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCG has converged with residual 6.76266154187033e-07 at iteration 36\n"
          ]
        }
      ],
      "source": [
        "w0 = torch.zeros(m).to(device)\n",
        "model = InducingKRR(xtr, btr, xtst, btst, kernel_params, inducing_pts, lambd, task, w0, device)\n",
        "opt = PCG(model, inducing=True, precond_params=precond_params_falkon)\n",
        "opt.run(pcg_iters)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fast_krr_env",
      "language": "python",
      "name": "fast_krr_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
